{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pycocotools.coco import COCO\nimport os\nfrom glob import glob\nimport pydicom\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap \nimport cv2\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchvision import transforms\nimport numpy as np\nfrom tqdm import tqdm_notebook as tqdm\nfrom numpy import transpose\nimport math\nfrom math import log, pi, sqrt\nfrom functools import partial\n\nimport torch\nfrom torch import nn, einsum\nimport torch.nn.functional as F\nimport PIL\n  \nimport torch\nimport torch.nn as nn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"class CocoDataset(Dataset):\n    \"\"\"Low-Dose CT dataset.\"\"\"\n\n    def __init__(self,instance_path='../input/coco-2017-dataset/coco2017/annotations/instances_train2017.json',\n                 img_path='../input/coco-2017-dataset/coco2017/train2017',\n                 transform=None,):\n        \"\"\"\n        Args:\n            root_dir (string): Directory with all the images.\n            transform (callable, optional): Optional transform to be applied on a sample.\n        \"\"\"\n        self.img_paths = img_path\n        self.coco=COCO(instance_path)\n        self.catIDs = self.coco.getCatIds()\n        # print(catIDs)\n        imgIds = []\n        for x in self.catIDs:\n            imgIds += self.coco.getImgIds(catIds = [x])\n        self.img_id = imgIds\n        self.len = len(imgIds)\n        print(self.len)\n        \n        if transform:\n            self.transform = transform\n        else:\n            self.transform = transforms.Compose([\n#                 transforms.Rescale(255),\n                transforms.ToTensor()\n            ])\n\n    def __len__(self):\n        return self.len\n\n    def __getitem__(self, idx):\n        if torch.is_tensor(idx):\n            idx = idx.tolist()\n        img = self.coco.loadImgs(self.img_id[idx])[0]\n        image= plt.imread('{}/{}'.format(self.img_paths, img['file_name']))/255.0\n        mask = np.zeros((img['height'],img['width']))\n        annIds = self.coco.getAnnIds(imgIds=img['id'], catIds=self.catIDs, iscrowd=None)\n        anns = self.coco.loadAnns(annIds)\n        for i in range(len(anns)):\n            mask = np.maximum(self.coco.annToMask(anns[i]), mask)\n        mask = cv2.resize(mask, (64,64))\n        image = cv2.resize(image, (64,64)).astype(np.float32)\n        if(len(image.shape)==2):\n            image = cv2.merge([image, image, image])\n        mask = (mask > 0.5).astype(np.float32)\n        \n        if self.transform:\n            image = self.transform(image)\n            mask = self.transform(mask)\n            \n        sample = (image, mask)\n\n        return sample\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_set = CocoDataset()\nval_set = CocoDataset('../input/coco-2017-dataset/coco2017/annotations/instances_val2017.json', '../input/coco-2017-dataset/coco2017/val2017')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 50\nWORKERS = 0\nSHUFFLE = True\ntrain_loader = DataLoader(train_set,  batch_size=BATCH_SIZE,\n                        shuffle=SHUFFLE, num_workers=WORKERS)\nval_loader = DataLoader(val_set,  batch_size=BATCH_SIZE,\n                        shuffle=SHUFFLE, num_workers=WORKERS)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DenseLayer(nn.Sequential):\n    def __init__(self, in_channels, growth_rate):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm2d(in_channels))\n        self.add_module('relu', nn.ReLU(True))\n        self.add_module('conv', nn.Conv2d(in_channels, growth_rate, kernel_size=3,\n                                          stride=1, padding=1, bias=True))\n        self.add_module('drop', nn.Dropout2d(0.2))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\nclass DenseBlock(nn.Module):\n    def __init__(self, in_channels, growth_rate, n_layers, upsample=False):\n        super().__init__()\n        self.upsample = upsample\n        self.layers = nn.ModuleList([DenseLayer(\n            in_channels + i*growth_rate, growth_rate)\n            for i in range(n_layers)])\n\n    def forward(self, x):\n        if self.upsample:\n            new_features = []\n            #we pass all previous activations into each dense layer normally\n            #But we only store each dense layer's output in the new_features array\n            for layer in self.layers:\n                out = layer(x)\n                x = torch.cat([x, out], 1)\n                new_features.append(out)\n            return torch.cat(new_features,1)\n        else:\n            for layer in self.layers:\n                out = layer(x)\n                x = torch.cat([x, out], 1) # 1 = channel axis\n            return x\n\n\nclass TransitionDown(nn.Sequential):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.add_module('norm', nn.BatchNorm2d(num_features=in_channels))\n        self.add_module('relu', nn.ReLU(inplace=True))\n        self.add_module('conv', nn.Conv2d(in_channels, in_channels,\n                                          kernel_size=1, stride=1,\n                                          padding=0, bias=True))\n        self.add_module('drop', nn.Dropout2d(0.2))\n        self.add_module('maxpool', nn.MaxPool2d(2))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\nclass TransitionUp(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        self.convTrans = nn.ConvTranspose2d(\n            in_channels=in_channels, out_channels=out_channels,\n            kernel_size=3, stride=2, padding=0, bias=True)\n\n    def forward(self, x, skip):\n        out = self.convTrans(x)\n        out = center_crop(out, skip.size(2), skip.size(3))\n        out = torch.cat([out, skip], 1)\n        return out\n\n\nclass Bottleneck(nn.Sequential):\n    def __init__(self, in_channels, growth_rate, n_layers):\n        super().__init__()\n        self.add_module('bottleneck', DenseBlock(\n            in_channels, growth_rate, n_layers, upsample=True))\n\n    def forward(self, x):\n        return super().forward(x)\n\n\ndef center_crop(layer, max_height, max_width):\n    _, _, h, w = layer.size()\n    xy1 = (w - max_width) // 2\n    xy2 = (h - max_height) // 2\n    return layer[:, :, xy2:(xy2 + max_height), xy1:(xy1 + max_width)]\n\nclass FCDenseNet(nn.Module):\n    def __init__(self, in_channels=3, down_blocks=(5,5,5,5,5),\n                 up_blocks=(5,5,5,5,5), bottleneck_layers=5,\n                 growth_rate=16, out_chans_first_conv=48, n_classes=1):\n        super().__init__()\n        self.down_blocks = down_blocks\n        self.up_blocks = up_blocks\n        cur_channels_count = 0\n        skip_connection_channel_counts = []\n\n        ## First Convolution ##\n\n        self.add_module('firstconv', nn.Conv2d(in_channels=in_channels,\n                  out_channels=out_chans_first_conv, kernel_size=3,\n                  stride=1, padding=1, bias=True))\n        cur_channels_count = out_chans_first_conv\n\n        #####################\n        # Downsampling path #\n        #####################\n\n        self.denseBlocksDown = nn.ModuleList([])\n        self.transDownBlocks = nn.ModuleList([])\n        for i in range(len(down_blocks)):\n            self.denseBlocksDown.append(\n                DenseBlock(cur_channels_count, growth_rate, down_blocks[i]))\n            cur_channels_count += (growth_rate*down_blocks[i])\n            skip_connection_channel_counts.insert(0,cur_channels_count)\n            self.transDownBlocks.append(TransitionDown(cur_channels_count))\n\n        #####################\n        #     Bottleneck    #\n        #####################\n\n        self.add_module('bottleneck',Bottleneck(cur_channels_count,\n                                     growth_rate, bottleneck_layers))\n        prev_block_channels = growth_rate*bottleneck_layers\n        cur_channels_count += prev_block_channels\n\n        #######################\n        #   Upsampling path   #\n        #######################\n\n        self.transUpBlocks = nn.ModuleList([])\n        self.denseBlocksUp = nn.ModuleList([])\n        for i in range(len(up_blocks)-1):\n            self.transUpBlocks.append(TransitionUp(prev_block_channels, prev_block_channels))\n            cur_channels_count = prev_block_channels + skip_connection_channel_counts[i]\n\n            self.denseBlocksUp.append(DenseBlock(\n                cur_channels_count, growth_rate, up_blocks[i],\n                    upsample=True))\n            prev_block_channels = growth_rate*up_blocks[i]\n            cur_channels_count += prev_block_channels\n\n        ## Final DenseBlock ##\n\n        self.transUpBlocks.append(TransitionUp(\n            prev_block_channels, prev_block_channels))\n        cur_channels_count = prev_block_channels + skip_connection_channel_counts[-1]\n\n        self.denseBlocksUp.append(DenseBlock(\n            cur_channels_count, growth_rate, up_blocks[-1],\n                upsample=False))\n        cur_channels_count += growth_rate*up_blocks[-1]\n\n        ## Softmax ##\n\n        self.finalConv = nn.Conv2d(in_channels=cur_channels_count,\n               out_channels=n_classes, kernel_size=1, stride=1,\n                   padding=0, bias=True)\n        self.sig = nn.Sigmoid()\n    def forward(self, x):\n        out = self.firstconv(x)\n\n        skip_connections = []\n        for i in range(len(self.down_blocks)):\n            out = self.denseBlocksDown[i](out)\n            skip_connections.append(out)\n            out = self.transDownBlocks[i](out)\n\n        out = self.bottleneck(out)\n        for i in range(len(self.up_blocks)):\n            skip = skip_connections.pop()\n            out = self.transUpBlocks[i](out, skip)\n            out = self.denseBlocksUp[i](out)\n\n        out = self.finalConv(out)\n        out = self.sig(out)\n        return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = FCDenseNet()\nif torch.cuda.is_available():\n    model = model.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Binary cross entropy loss function\ncriterion = nn.BCELoss()\nif torch.cuda.is_available():\n    criterion = criterion.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Adam Optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# number of epochs to train the model\nn_epochs = 6\n\nfor epoch in range(1, n_epochs+1):\n    # monitor training loss\n    train_loss = 0.0\n#     train the model\n    bar = tqdm(train_loader)\n    for data in bar:\n        img, mask = data\n        if torch.cuda.is_available():\n            img, mask = img.cuda(), mask.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass\n        outputs = model(img)\n        loss = criterion(outputs, mask)\n        # backward pass\n        loss.backward()\n        # optimization step (parameter update)\n        optimizer.step()\n        # update running training loss\n        train_loss += loss.item()\n        bar.set_description(\"Processing %s\" % loss.item())\n    if epoch%2==0:\n        torch.save(model, \"./modelComplete\"+str(epoch))\n    valid_loss = 0.0\n    val_bar = tqdm(val_loader)\n    for data in val_bar:\n        \n        img, mask = data\n        if torch.cuda.is_available():\n            img, mask = img.cuda(), mask.cuda()\n        \n        target = model(img)\n       \n        loss = criterion(target,mask)\n        valid_loss += loss.item()\n        val_bar.set_description(\"Processing %s\" % loss.item())\n            \n    # print avg training statistics \n    train_loss = train_loss/len(train_loader)\n    valid_loss = valid_loss/len(val_loader)\n    print('Epoch: {} \\tTraining Loss: {:.8f} \\tValidation Loss: {:.8f} \\t'.format(\n        epoch, \n        train_loss,valid_loss\n        ))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}